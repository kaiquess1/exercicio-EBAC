{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "* ### Cinco diferenças entre Ada-boost e Gradient-Boost Machine\n",
        "\n",
        " 1. Ada-boost são florestas de stump e no Gradient-boost Machine são floresta de arvores completas;\n",
        " 2. No Ada-boost o primeiro passo para criar o modelo é o stump e no Gradient-boost o primeiro passo é a média do Y;\n",
        " 3. No Ada-boost cada resposta possui um peso diferente e no Gradient-boost todas as arvores possui um multiplicador coumum chamado learning-rate(eta);\n",
        " 4. Na Ada-boost a evolução /melhoria é feita a partir das observações classificadas de forma errada e no Gradient-boost evolue por meio dos residuos das iterações anteriores;\n",
        " 5. Em Ada-boost as resposta dos stumps são independentes e já no Gradient-boost o contrario; \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8xGJgOgcVbBR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cBjxl4t_zMC6"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X,y=datasets.load_breast_cancer(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33,stratify=y, random_state=42)\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "model=clf.fit(X_train,y_train)\n",
        "y_pred=model.predict(X_test)\n",
        "previsao=accuracy_score(y_test,y_pred)\n",
        "\n",
        "print('Acurácia do modelo usando Decision Tree {:.2f}%'.format(previsao*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxD5595KJOoB",
        "outputId": "9bddf7af-60a8-44af-cd30-15d44bb97cbc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia do modelo usando Decision Tree 90.43%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ada=AdaBoostClassifier(n_estimators=100,learning_rate=1.6,random_state=42)\n",
        "model=ada.fit(X_train,y_train)\n",
        "y_ada=ada.predict(X_test)\n",
        "previsao2=accuracy_score(y_test,y_ada)\n",
        "\n",
        "print('Acurácia do modelo usando Adaboost {:.2f}%'.format(previsao2*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwrhs75TUiV3",
        "outputId": "cd242b6d-7ec6-450f-842a-8ca17e75ff32"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia do modelo usando Adaboost 96.81%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gb=GradientBoostingClassifier(n_estimators=131,subsample=1.0,learning_rate=0.50,max_depth=3,random_state=42)\n",
        "modelo=gb.fit(X_train,y_train)\n",
        "y_gb=gb.predict(X_test)\n",
        "previsao3=accuracy_score(y_test,y_gb)\n",
        "print('Acurácia do modelo usando Gb {:.2f}%'.format(previsao3*100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZ__st4Di7ba",
        "outputId": "69a0956d-b684-42e2-f3bb-bde6d9aa4542"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia do modelo usando Gb 96.28%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ### Cinco hyperparametros importantes do Gradient Boost Machine\n",
        "\n",
        "1. n_estimators;\n",
        "2. learning_rate;\n",
        "3. subsample;\n",
        "4. max_depth;\n",
        "5. criterion;\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VE8mj059cmKa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* A maior diferença é que ele cria uma amoatragem sem reposição de forma aleatoria, diminuindo a quantidade de linhas e consequentemente acelerando o tempo de treinamento do modelo. "
      ],
      "metadata": {
        "id": "zAT4xkEGl8xs"
      }
    }
  ]
}